# -*- coding: utf-8 -*-
"""
Match Parser - Parser cho cÃ¡c tráº­n Ä‘áº¥u sáº¯p diá»…n ra
"""

from parsers.base_parser import BaseParser
import logging
from datetime import datetime, timedelta
import re
import time
from urllib.parse import urljoin
from config import CATEGORY_MAPPING, PAGE_LOAD_DELAY

logger = logging.getLogger(__name__)


class VnExpressMatchParser(BaseParser):
    """Parser cho lá»‹ch thi Ä‘áº¥u VnExpress"""
    
    def __init__(self):
        super().__init__('VnExpress Matches', 'https://vnexpress.net/the-thao/ngoai-hang-anh/lich-thi-dau')
    
    def get_tournament_links(self):
        """Láº¥y danh sÃ¡ch cÃ¡c link giáº£i Ä‘áº¥u tá»« trang chÃ­nh"""
        html = self.get_page(self.base_url)
        if not html:
            return []
        
        soup = self.parse_soup(html)
        tournament_links = []
        
        # TÃ¬m cÃ¡c link Ä‘áº¿n trang giáº£i Ä‘áº¥u
        # Pattern: /the-thao/du-lieu-bong-da/giai-dau/...
        links = soup.select('a[href*="/du-lieu-bong-da/giai-dau/"]')
        
        seen_urls = set()
        for link in links:
            href = link.get('href', '')
            if not href:
                continue
            
            # Táº¡o absolute URL
            if href.startswith('/'):
                href = 'https://vnexpress.net' + href
            elif not href.startswith('http'):
                continue
            
            # Bá» qua cÃ¡c URL trÃ¹ng láº·p
            if href in seen_urls:
                continue
            seen_urls.add(href)
            
            # Láº¥y tÃªn giáº£i Ä‘áº¥u tá»« text hoáº·c tá»« URL
            tournament_name = self.clean_text(link.get_text())
            if not tournament_name or len(tournament_name) < 3:
                # Láº¥y tá»« URL náº¿u khÃ´ng cÃ³ text
                parts = href.split('/')
                if len(parts) > 0:
                    tournament_name = parts[-1].replace('-', ' ').title()
            
            tournament_links.append({
                'url': href,
                'name': tournament_name
            })
        
        logger.info(f"âœ“ TÃ¬m tháº¥y {len(tournament_links)} giáº£i Ä‘áº¥u tá»« VnExpress")
        return tournament_links
    
    def get_upcoming_matches(self, limit=50, days_range=None):
        """Láº¥y danh sÃ¡ch cÃ¡c tráº­n Ä‘áº¥u sáº¯p diá»…n ra"""
        matches = []
        
        # Parse tá»« trang Ngoáº¡i Háº¡ng Anh
        logger.info(f"ğŸ“¥ Äang táº£i trang: {self.base_url}")
        html = self.get_page(self.base_url)
        if not html:
            logger.warning("âš  KhÃ´ng thá»ƒ láº¥y HTML tá»« trang")
            return []
        
        soup = self.parse_soup(html)
        logger.info(f"âœ“ ÄÃ£ parse HTML thÃ nh cÃ´ng")
        
        # Thá»­ tÃ¬m lá»‹ch thi Ä‘áº¥u trá»±c tiáº¿p trong trang (widget, table, etc.)
        match_containers = soup.select(
            '.schedule-table, .match-list, .fixture-list, '
            '.list-match, table.schedule, .match-schedule, '
            '[class*="schedule"], [class*="fixture"], [class*="match-list"]'
        )
        
        if match_containers:
            logger.info(f"âœ“ TÃ¬m tháº¥y {len(match_containers)} container chá»©a lá»‹ch thi Ä‘áº¥u")
            for container in match_containers:
                container_matches = self.extract_matches_from_text(
                    container.get_text(), 
                    'Ngoáº¡i Háº¡ng Anh'
                )
                if container_matches:
                    logger.info(f"  âœ“ Parse Ä‘Æ°á»£c {len(container_matches)} tráº­n tá»« container")
                matches.extend(container_matches)
        
        # Parse tá»« cÃ¡c bÃ i viáº¿t - THá»¬ Táº¤T Cáº¢ cÃ¡c bÃ i viáº¿t, khÃ´ng chá»‰ nhá»¯ng bÃ i cÃ³ tá»« khÃ³a
        article_items = soup.select('.item-news, article, .news-item, .list_news li, .item_normal, .item-news-common')[:limit * 3]
        logger.info(f"âœ“ TÃ¬m tháº¥y {len(article_items)} bÃ i viáº¿t Ä‘á»ƒ parse")
        
        articles_checked = 0
        for item in article_items:
            try:
                title_tag = item.select_one('.title-news a, h3 a, .title a, a.title, a')
                if not title_tag:
                    continue
                
                title = self.clean_text(title_tag.get_text())
                url = title_tag.get('href', '')
                
                if not url or not title:
                    continue
                
                # Táº¡o absolute URL
                if url.startswith('/'):
                    url = 'https://vnexpress.net' + url
                elif not url.startswith('http'):
                    continue
                
                articles_checked += 1
                
                # Parse tá»« title trÆ°á»›c (nhanh hÆ¡n)
                title_matches = self.extract_matches_from_text(title, 'Ngoáº¡i Háº¡ng Anh')
                if title_matches:
                    logger.info(f"  âœ“ TÃ¬m tháº¥y {len(title_matches)} tráº­n trong title: {title[:50]}...")
                    matches.extend(title_matches)
                    if len(matches) >= limit:
                        break
                
                # Kiá»ƒm tra náº¿u lÃ  bÃ i vá» lá»‹ch thi Ä‘áº¥u hoáº·c cÃ³ tá»« khÃ³a liÃªn quan
                title_lower = title.lower()
                keywords = [
                    'lá»‹ch thi Ä‘áº¥u', 'lá»‹ch Ä‘áº¥u', 'fixture', 'schedule',
                    'vs', 'Ä‘áº¥u', 'gáº·p', 'match', 'premier league',
                    'ngoáº¡i háº¡ng anh', 'vÃ²ng', 'round', 'lá»‹ch', 'vÃ²ng Ä‘áº¥u'
                ]
                
                if any(keyword in title_lower for keyword in keywords):
                    match_data = self.parse_match_from_article(url, title)
                    if match_data:
                        if isinstance(match_data, list):
                            logger.info(f"  âœ“ Parse Ä‘Æ°á»£c {len(match_data)} tráº­n tá»« bÃ i: {title[:50]}...")
                            matches.extend(match_data)
                        else:
                            logger.info(f"  âœ“ Parse Ä‘Æ°á»£c 1 tráº­n tá»« bÃ i: {title[:50]}...")
                            matches.append(match_data)
                        
                        if len(matches) >= limit:
                            break
                        
            except Exception as e:
                logger.debug(f"  âš  Lá»—i parse article: {e}")
                continue
        
        logger.info(f"âœ“ ÄÃ£ kiá»ƒm tra {articles_checked} bÃ i viáº¿t")
        
        # Náº¿u váº«n chÆ°a Ä‘á»§, thá»­ parse tá»« toÃ n bá»™ ná»™i dung trang
        if len(matches) < limit:
            logger.info("ğŸ“„ Äang parse tá»« toÃ n bá»™ ná»™i dung trang...")
            page_text = soup.get_text()
            text_matches = self.extract_matches_from_text(page_text, 'Ngoáº¡i Háº¡ng Anh')
            if text_matches:
                logger.info(f"  âœ“ Parse Ä‘Æ°á»£c {len(text_matches)} tráº­n tá»« ná»™i dung trang")
            matches.extend(text_matches)
        
        # Loáº¡i bá» trÃ¹ng láº·p dá»±a trÃªn home_team vÃ  away_team
        seen = set()
        unique_matches = []
        for match in matches:
            key = (match.get('home_team_name', '').lower(), match.get('away_team_name', '').lower())
            if key not in seen and key[0] and key[1]:
                seen.add(key)
                unique_matches.append(match)
        matches = unique_matches
        
        # Filter theo days_range náº¿u cÃ³
        if days_range and matches:
            start_date = datetime.now() - timedelta(days=days_range[0])
            end_date = datetime.now() + timedelta(days=days_range[1])
            filtered_matches = []
            for match in matches:
                match_date = match.get('match_date')
                if isinstance(match_date, datetime):
                    if start_date <= match_date <= end_date:
                        filtered_matches.append(match)
                else:
                    # Náº¿u khÃ´ng cÃ³ ngÃ y, giá»¯ láº¡i (sáº½ dÃ¹ng default date)
                    filtered_matches.append(match)
            matches = filtered_matches
        
        logger.info(f"âœ“ Tá»•ng cá»™ng tÃ¬m tháº¥y {len(matches)} tráº­n Ä‘áº¥u tá»« VnExpress")
        return matches[:limit]
    
    def parse_tournament_matches(self, tournament_url, tournament_name, limit=10):
        """Parse lá»‹ch thi Ä‘áº¥u tá»« trang giáº£i Ä‘áº¥u cá»¥ thá»ƒ"""
        html = self.get_page(tournament_url)
        if not html:
            return []
        
        soup = self.parse_soup(html)
        matches = []
        
        # TÃ¬m cÃ¡c pháº§n tá»­ cÃ³ thá»ƒ chá»©a thÃ´ng tin tráº­n Ä‘áº¥u
        # Thá»­ nhiá»u selector khÃ¡c nhau
        match_selectors = [
            '.match', '.fixture', '.schedule-item', '.match-item',
            '[class*="match"]', '[class*="fixture"]', '[class*="schedule"]',
            'table tr', '.list-match li', '.match-list .item'
        ]
        
        match_elements = []
        for selector in match_selectors:
            elements = soup.select(selector)
            if elements:
                match_elements = elements
                logger.info(f"  âœ“ TÃ¬m tháº¥y {len(elements)} pháº§n tá»­ vá»›i selector: {selector}")
                break
        
        # Náº¿u khÃ´ng tÃ¬m tháº¥y pháº§n tá»­ match cá»¥ thá»ƒ, parse tá»« toÃ n bá»™ ná»™i dung
        if not match_elements:
            # TÃ¬m cÃ¡c pattern trong text
            content_text = soup.get_text()
            matches_found = self.extract_matches_from_text(content_text, tournament_name)
            return matches_found[:limit]
        
        # Parse tá»« cÃ¡c pháº§n tá»­ match
        for element in match_elements[:limit]:
            try:
                match_data = self.parse_match_element(element, tournament_name)
                if match_data:
                    matches.append(match_data)
            except Exception as e:
                logger.debug(f"  âš  KhÃ´ng parse Ä‘Æ°á»£c element: {e}")
                continue
        
        return matches[:limit]
    
    def is_valid_team_name(self, name):
        """Kiá»ƒm tra xem tÃªn cÃ³ pháº£i lÃ  tÃªn Ä‘á»™i bÃ³ng há»£p lá»‡ khÃ´ng"""
        if not name or len(name.strip()) < 2:
            return False
        
        name = name.strip()
        name_lower = name.lower()
        
        # Loáº¡i bá» cÃ¡c tá»« khÃ´ng pháº£i tÃªn Ä‘á»™i (strict hÆ¡n)
        invalid_keywords = [
            'vnexpress', 'thá»ƒ thao', 'lá»‹ch thi Ä‘áº¥u', 'lá»‹ch Ä‘áº¥u', 'má»›i nháº¥t',
            'tin tá»©c', 'káº¿t quáº£', 'báº£ng xáº¿p háº¡ng', 'chÃ¢n dung', 'phÃ¢n tÃ­ch',
            'hÃ´m nay', 'ngÃ y mai', 'cuá»™c', 'tráº­n', 'Ä‘áº¥u', 'gáº·p', 'vÃ ', 'hoáº·c',
            'xem', 'video', 'áº£nh', 'clip', 'highlight', 'tá»•ng há»£p'
        ]
        
        # Kiá»ƒm tra cÃ¡c tá»« khÃ´ng há»£p lá»‡ (chá»‰ reject náº¿u lÃ  tá»« Ä‘Æ¡n láº» hoáº·c chá»©a tá»« Ä‘áº§u)
        for keyword in invalid_keywords:
            if name_lower == keyword or name_lower.startswith(keyword + ' ') or name_lower.endswith(' ' + keyword):
                return False
        
        # TÃªn Ä‘á»™i thÆ°á»ng khÃ´ng quÃ¡ dÃ i
        words = name.split()
        if len(words) > 6:  # Cho phÃ©p tÃªn Ä‘á»™i dÃ i hÆ¡n má»™t chÃºt
            return False
        
        # TÃªn Ä‘á»™i khÃ´ng nÃªn chá»‰ lÃ  sá»‘ hoáº·c kÃ½ tá»± Ä‘áº·c biá»‡t
        if name.replace(' ', '').replace('.', '').replace('-', '').isdigit():
            return False
        
        # TÃªn Ä‘á»™i pháº£i cÃ³ Ã­t nháº¥t 1 chá»¯ cÃ¡i
        if not any(c.isalpha() for c in name):
            return False
        
        return True
    
    def parse_match_element(self, element, tournament_name):
        """Parse má»™t pháº§n tá»­ match thÃ nh dict"""
        text = element.get_text()
        current_year = datetime.now().year
        
        # TÃ¬m pattern: "Team A vs Team B" hoáº·c "Team A - Team B"
        # Cáº£i thiá»‡n pattern Ä‘á»ƒ match tá»‘t hÆ¡n
        match_pattern = r'([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹\s\-\.]{1,30}?)\s*(?:vs|v\.s|Ä‘áº¥u|gáº·p|[-â€“â€”])\s*([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹\s\-\.]{1,30}?)'
        match = re.search(match_pattern, text, re.IGNORECASE)
        
        if not match:
            return None
        
        home_team = self.clean_text(match.group(1))
        away_team = self.clean_text(match.group(2))
        
        # Validate tÃªn Ä‘á»™i
        if not self.is_valid_team_name(home_team) or not self.is_valid_team_name(away_team):
            return None
        
        # TÃ¬m ngÃ y giá» trong text
        match_date = self.extract_match_date(text, current_year)
        
        # TÃ¬m logo Ä‘á»™i (náº¿u cÃ³)
        home_logo = None
        away_logo = None
        imgs = element.select('img')
        if len(imgs) >= 2:
            home_logo = imgs[0].get('src') or imgs[0].get('data-src')
            away_logo = imgs[1].get('src') or imgs[1].get('data-src')
        
        return {
            'home_team_name': home_team,
            'away_team_name': away_team,
            'home_team_logo': home_logo,
            'away_team_logo': away_logo,
            'match_date': match_date,
            'tournament_name': tournament_name,
            'category_id': self.detect_category_from_tournament(tournament_name),
            'status': 'scheduled'
        }
    
    def extract_matches_from_text(self, text, tournament_name, current_year=None):
        """TrÃ­ch xuáº¥t cÃ¡c tráº­n Ä‘áº¥u tá»« text báº±ng regex"""
        matches = []
        
        if current_year is None:
            current_year = datetime.now().year
        
        if not text or len(text.strip()) < 10:
            return matches
        
        # Pattern: "Team A vs Team B" hoáº·c "Team A - Team B"
        # Cáº£i thiá»‡n pattern Ä‘á»ƒ match tá»‘t hÆ¡n vá»›i tÃªn Ä‘á»™i Premier League
        # Cho phÃ©p sá»‘ trong tÃªn Ä‘á»™i (nhÆ° "Man City", "Man Utd")
        match_patterns = [
            # Pattern chÃ­nh: Team vs Team
            r'([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹0-9\s\-\.]{1,35}?)\s+(?:vs|v\.s|Ä‘áº¥u|gáº·p|v|VS)\s+([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹0-9\s\-\.]{1,35}?)',
            # Pattern vá»›i dáº¥u gáº¡ch ngang
            r'([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹0-9\s\-\.]{1,35}?)\s*[-â€“â€”]\s*([A-Za-zÃ€-á»¹][A-Za-zÃ€-á»¹0-9\s\-\.]{1,35}?)',
        ]
        
        found_matches = []
        for pattern in match_patterns:
            matches_found = re.findall(pattern, text, re.IGNORECASE)
            found_matches.extend(matches_found)
        
        # Loáº¡i bá» trÃ¹ng láº·p
        seen_pairs = set()
        unique_matches = []
        for match in found_matches:
            pair = (match[0].strip().lower(), match[1].strip().lower())
            if pair not in seen_pairs:
                seen_pairs.add(pair)
                unique_matches.append(match)
        
        for match in unique_matches[:30]:  # TÄƒng giá»›i háº¡n lÃªn 30 tráº­n
            home_team = self.clean_text(match[0])
            away_team = self.clean_text(match[1])
            
            # Loáº¡i bá» cÃ¡c tá»« khÃ´ng há»£p lá»‡ á»Ÿ Ä‘áº§u/cuá»‘i
            home_team = home_team.strip(' .,;:!?()[]{}"\'-â€“â€”')
            away_team = away_team.strip(' .,;:!?()[]{}"\'-â€“â€”')
            
            # Validate tÃªn Ä‘á»™i
            if not self.is_valid_team_name(home_team) or not self.is_valid_team_name(away_team):
                continue
            
            # TÃ¬m ngÃ y giá» gáº§n nháº¥t
            match_date = self.extract_match_date(text, current_year)
            
            matches.append({
                'home_team_name': home_team,
                'away_team_name': away_team,
                'match_date': match_date,
                'tournament_name': tournament_name,
                'category_id': self.detect_category_from_tournament(tournament_name),
                'status': 'scheduled'
            })
        
        return matches
    
    def detect_category_from_tournament(self, tournament_name):
        """PhÃ¡t hiá»‡n category tá»« tÃªn giáº£i Ä‘áº¥u"""
        name_lower = tournament_name.lower()
        
        # Mapping cÃ¡c giáº£i Ä‘áº¥u
        if any(x in name_lower for x in ['premier', 'ngoáº¡i háº¡ng anh', 'fa cup', 'cup liÃªn Ä‘oÃ n']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['champion', 'europa', 'c1', 'c2']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['la liga', 'laliga', 'cup nhÃ  vua']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['bundesliga', 'cup qg Ä‘á»©c']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['serie a', 'cup qg italy']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['ligue', 'cup qg phÃ¡p']):
            return 1  # BÃ³ng Ä‘Ã¡
        elif any(x in name_lower for x in ['v-league', 'vleague']):
            return 1  # BÃ³ng Ä‘Ã¡
        
        return 1  # Default: BÃ³ng Ä‘Ã¡
    
    def parse_match_from_article(self, url, title):
        """Parse tráº­n Ä‘áº¥u tá»« bÃ i viáº¿t vá» lá»‹ch thi Ä‘áº¥u"""
        try:
            html = self.get_page(url)
            if not html:
                return None
            
            soup = self.parse_soup(html)
            content_text = soup.get_text()
            
            # TÃ¬m cÃ¡c tráº­n Ä‘áº¥u trong ná»™i dung
            # Pattern: "Team A vs Team B" hoáº·c "Team A - Team B"
            matches = []
            
            # TÃ¬m ngÃ y giá» trong bÃ i viáº¿t
            date_patterns = [
                r'(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{4})',  # dd/mm/yyyy
                r'(\d{4})[\/\-](\d{1,2})[\/\-](\d{1,2})',  # yyyy/mm/dd
            ]
            
            time_patterns = [
                r'(\d{1,2}):(\d{2})',  # HH:MM
            ]
            
            # Parse tá»« title vÃ  content
            # VÃ­ dá»¥: "Lá»‹ch thi Ä‘áº¥u Premier League: Man City vs Liverpool 15/01/2025 20:00"
            match_pattern = r'([A-Za-zÃ€-á»¹\s]+?)\s*(?:vs|v\.s|Ä‘áº¥u|gáº·p|-)\s*([A-Za-zÃ€-á»¹\s]+?)(?:\s+\d{1,2}[\/\-]\d{1,2})?'
            
            found_matches = re.findall(match_pattern, title + ' ' + content_text[:500], re.IGNORECASE)
            
            for match in found_matches[:10]:  # Giá»›i háº¡n 10 tráº­n
                home_team = match[0].strip()
                away_team = match[1].strip()
                
                if len(home_team) < 3 or len(away_team) < 3:
                    continue
                
                # TÃ¬m ngÃ y giá»
                match_date = self.extract_match_date(content_text)
                
                matches.append({
                    'home_team_name': home_team,
                    'away_team_name': away_team,
                    'match_date': match_date,
                    'tournament_name': self.extract_tournament(title, content_text),
                    'category_id': self.detect_category(title, content_text, url),
                    'status': 'scheduled'
                })
            
            return matches if matches else None
            
        except Exception as e:
            logger.error(f"âœ— Lá»—i parse match from article {url}: {e}")
            return None
    
    def extract_match_date(self, text, current_year=None):
        """TrÃ­ch xuáº¥t ngÃ y giá» tá»« text"""
        try:
            if current_year is None:
                current_year = datetime.now().year
            
            # TÃ¬m ngÃ y giá» trong text
            # Pattern: dd/mm/yyyy HH:MM hoáº·c yyyy-mm-dd HH:MM:SS
            date_pattern = r'(\d{1,2})[\/\-](\d{1,2})[\/\-](\d{4})\s+(\d{1,2}):(\d{2})'
            match = re.search(date_pattern, text)
            
            if match:
                day, month, year, hour, minute = match.groups()
                return datetime(int(year), int(month), int(day), int(hour), int(minute))
            
            # Pattern khÃ¡c: yyyy-mm-dd HH:MM
            date_pattern2 = r'(\d{4})[\/\-](\d{1,2})[\/\-](\d{1,2})\s+(\d{1,2}):(\d{2})'
            match = re.search(date_pattern2, text)
            
            if match:
                year, month, day, hour, minute = match.groups()
                return datetime(int(year), int(month), int(day), int(hour), int(minute))
            
            # Pattern: dd/mm HH:MM (khÃ´ng cÃ³ nÄƒm, dÃ¹ng current_year)
            date_pattern3 = r'(\d{1,2})[\/\-](\d{1,2})\s+(\d{1,2}):(\d{2})'
            match = re.search(date_pattern3, text)
            
            if match:
                day, month, hour, minute = match.groups()
                return datetime(current_year, int(month), int(day), int(hour), int(minute))
            
            # Máº·c Ä‘á»‹nh: hÃ´m nay + 1 ngÃ y, 20:00
            return datetime.now().replace(hour=20, minute=0, second=0, microsecond=0) + timedelta(days=1)
            
        except Exception as e:
            logger.warning(f"âš  KhÃ´ng parse Ä‘Æ°á»£c ngÃ y giá»: {e}")
            return datetime.now().replace(hour=20, minute=0, second=0, microsecond=0) + timedelta(days=1)
    
    def extract_tournament(self, title, content):
        """TrÃ­ch xuáº¥t tÃªn giáº£i Ä‘áº¥u"""
        tournaments = [
            'Premier League', 'La Liga', 'Serie A', 'Bundesliga',
            'Champions League', 'Europa League', 'World Cup',
            'V-League', 'AFF Cup', 'SEA Games',
            'Ngoáº¡i háº¡ng Anh', 'C1', 'C2'
        ]
        
        text = (title + ' ' + content[:200]).lower()
        for tournament in tournaments:
            if tournament.lower() in text:
                return tournament
        
        # Náº¿u URL chá»©a "ngoai-hang-anh", máº·c Ä‘á»‹nh lÃ  Ngoáº¡i Háº¡ng Anh
        if hasattr(self, 'base_url') and 'ngoai-hang-anh' in self.base_url.lower():
            return 'Ngoáº¡i Háº¡ng Anh'
        
        return 'Giáº£i Ä‘áº¥u'


